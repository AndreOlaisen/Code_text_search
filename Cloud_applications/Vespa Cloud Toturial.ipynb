{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from random import random\n",
    "import time\n",
    "import multiprocessing\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vespa.package import Document, Field\n",
    "\n",
    "document = Document(\n",
    "    fields=[\n",
    "        Field(name = \"id\", type = \"string\", indexing = [\"attribute\", \"summary\"]),\n",
    "        Field(name = \"title\", type = \"string\", indexing = [\"index\", \"summary\"], index = \"enable-bm25\"),\n",
    "        Field(name = \"body\", type = \"string\", indexing = [\"index\", \"summary\"], index = \"enable-bm25\"),\n",
    "        Field(name = \"body_length\", type = \"int\", indexing = [\"attribute\", \"summary\"]),\n",
    "        Field(name = \"title_embedding\", type = \"tensor<float>(x[768]) \", indexing = [\"attribute\", \"summary\"])\n",
    "    ]\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vespa.package import Schema, FieldSet, RankProfile\n",
    "\n",
    "msmarco_schema = Schema(\n",
    "    name = \"msmarco\",\n",
    "    document = document,\n",
    "    fieldsets = [FieldSet(name = \"default\", fields = [\"title\", \"body\"])],\n",
    "    rank_profiles = [RankProfile(name = \"default\", first_phase = \"nativeRank(title, body)\"),\n",
    "                    RankProfile(name = \"bm25\", first_phase = \"bm25(title) + bm25(body)\")]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vespa.package import ApplicationPackage\n",
    "\n",
    "app_package = ApplicationPackage(name = \"msmarco\", schema=msmarco_schema)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vespa.package import VespaCloud\n",
    "\n",
    "            #C:\\Users\\User\\OneDrive - NTNU\\NTNU\\Prosjekt oppgave NLP\n",
    "path_key = \"C:\\\\Users\\\\User\\\\OneDrive - NTNU\\\\NTNU\\\\Prosjekt oppgave NLP\\\\Cloud_test\\\\\"\n",
    "file = \"andre.olaisen.tmartins-ntnu.pem\"\n",
    "\n",
    "\n",
    "# App name in Cloud\n",
    "app_name = \"andre-msmarco\"\n",
    "vespa_cloud = VespaCloud(\n",
    "    tenant=\"tmartins-ntnu\",\n",
    "    application=app_name,\n",
    "    key_location=path_key + file,\n",
    "    application_package=app_package\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\OneDrive - NTNU\\NTNU\\Prosjekt oppgave NLP\\Cloud_test\\sample_application_MSMARCO\n"
     ]
    }
   ],
   "source": [
    "name = \"sample_application_MSMARCO\"\n",
    "path = path_key + name\n",
    "print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deployment started in run 2 of dev-aws-us-east-1c for tmartins-ntnu.andre-msmarco.andre-olaisen. This may take about 15 minutes the first time.\n",
      "INFO    [14:11:13]  Deploying platform version 7.314.13 and application version unknown ...\n",
      "INFO    [14:11:15]  Deployment successful.\n",
      "INFO    [14:11:15]  Session 3931 for tenant 'tmartins-ntnu' prepared and activated.\n",
      "INFO    [14:11:15]  ######## Details for all nodes ########\n",
      "INFO    [14:11:15]  h5252d.dev.aws-us-east-1c.vespa-external.aws.oath.cloud: expected to be UP\n",
      "INFO    [14:11:15]  --- platform vespa/centos-tenant:7.314.13\n",
      "INFO    [14:11:15]  --- container on port 4080 has config generation 3931, wanted is 3931\n",
      "INFO    [14:11:15]  h5250c.dev.aws-us-east-1c.vespa-external.aws.oath.cloud: expected to be UP\n",
      "INFO    [14:11:15]  --- platform vespa/centos-tenant:7.314.13\n",
      "INFO    [14:11:15]  --- distributor on port 19111 has config generation 3928, wanted is 3931\n",
      "INFO    [14:11:15]  --- storagenode on port 19102 has config generation 3931, wanted is 3931\n",
      "INFO    [14:11:15]  --- searchnode on port 19107 has config generation 3931, wanted is 3931\n",
      "INFO    [14:11:15]  --- container-clustercontroller on port 19050 has config generation 3931, wanted is 3931\n",
      "INFO    [14:11:15]  h5251h.dev.aws-us-east-1c.vespa-external.aws.oath.cloud: expected to be UP\n",
      "INFO    [14:11:15]  --- platform vespa/centos-tenant:7.314.13\n",
      "INFO    [14:11:15]  --- logserver-container on port 4080 has config generation 3931, wanted is 3931\n",
      "INFO    [14:11:30]  Found endpoints:\n",
      "INFO    [14:11:30]  - dev.aws-us-east-1c\n",
      "INFO    [14:11:30]   |-- https://msmarco-container.andre-olaisen.andre-msmarco.tmartins-ntnu.aws-us-east-1c.dev.public.vespa.oath.cloud/ (cluster 'msmarco_container')\n",
      "INFO    [14:11:32]  Installation succeeded!\n"
     ]
    }
   ],
   "source": [
    "name = \"sample_application_MSMARCO\"\n",
    "\n",
    "path_key = \"C:\\\\Users\\\\User\\\\OneDrive - NTNU\\\\NTNU\\\\Prosjekt oppgave NLP\\\\Cloud_test\\\\\"\n",
    "\n",
    "\n",
    "app = vespa_cloud.deploy(\n",
    "    instance='andre-olaisen',\n",
    "    disk_folder=path_key\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(996, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pandas import read_csv\n",
    "\n",
    "docs = read_csv(\"https://thigm85.github.io/data/msmarco/docs.tsv\", sep = \"\\t\")\n",
    "docs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing sentence encoding models \n",
    "# link https://github.com/UKPLab/sentence-transformers#getting-started\n",
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer('distilbert-base-nli-mean-tokens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(docs[\"body\"][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feed_datapoint(row,i):\n",
    "    #if type(row[\"title\"]) != float:\n",
    "    #    embedding =  model.encode(row[\"title\"]).tolist()\n",
    "    #else:\n",
    "    #    embedding = [0 for _ in range(768)]\n",
    "    #print(len(row[\"title\"]), end = \"  \")\n",
    "    response = app.feed_data_point(\n",
    "        schema = \"msmarco\",\n",
    "        data_id = str(row[\"id\"]),\n",
    "        fields = {\n",
    "            \"id\": str(row[\"id\"]),\n",
    "            \"title\": str(row[\"title\"]),\n",
    "            \"body\": str(row[\"body\"]),\n",
    "            \"body_length\": len(row[\"body\"])#,\n",
    "            #\"title_embedding\": embedding\n",
    "        })\n",
    "    \n",
    "    return(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feed_datapoint(docs.iloc[1,:],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(docs[\"id\"])\n",
    "print(n)\n",
    "Parallel(n_jobs=num_cores)(delayed(app.feed_data_point)(\n",
    "        schema = \"msmarco\",\n",
    "        data_id = str(row[\"id\"]),\n",
    "        fields = {\n",
    "            \"id\": str(row[\"id\"]),\n",
    "            \"title\": str(row[\"title\"]),\n",
    "            \"body\": str(row[\"body\"]),\n",
    "            \"body_length\": len(row[\"body\"])#,\n",
    "            #\"title_embedding\": embedding\n",
    "        }) for idx, row in docs.iterrows())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"DATABRICKS_HOST\"] = \"<YOUR DATABRICKS HOST>\"\n",
    "os.environ[\"DATABRICKS_TOKEN\"] = \"<YOUR DATABRICKS TOKEN>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblibspark import register_spark\n",
    "register_spark()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install dill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill as pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "996\n"
     ]
    },
    {
     "ename": "PicklingError",
     "evalue": "Could not pickle the task to send it to the workers.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"C:\\Users\\User\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\joblib\\externals\\loky\\backend\\queues.py\", line 153, in _feed\n    obj_ = dumps(obj, reducers=reducers)\n  File \"C:\\Users\\User\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\joblib\\externals\\loky\\backend\\reduction.py\", line 271, in dumps\n    dump(obj, buf, reducers=reducers, protocol=protocol)\n  File \"C:\\Users\\User\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\joblib\\externals\\loky\\backend\\reduction.py\", line 264, in dump\n    _LokyPickler(file, reducers=reducers, protocol=protocol).dump(obj)\n  File \"C:\\Users\\User\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\joblib\\externals\\cloudpickle\\cloudpickle_fast.py\", line 563, in dump\n    return Pickler.dump(self, obj)\n  File \"C:\\Users\\User\\AppData\\Local\\Continuum\\anaconda3\\lib\\pickle.py\", line 437, in dump\n    self.save(obj)\n  File \"C:\\Users\\User\\AppData\\Local\\Continuum\\anaconda3\\lib\\pickle.py\", line 549, in save\n    self.save_reduce(obj=obj, *rv)\n  File \"C:\\Users\\User\\AppData\\Local\\Continuum\\anaconda3\\lib\\pickle.py\", line 662, in save_reduce\n    save(state)\n  File \"C:\\Users\\User\\AppData\\Local\\Continuum\\anaconda3\\lib\\pickle.py\", line 504, in save\n    f(self, obj) # Call unbound method with explicit self\n  File \"C:\\Users\\User\\AppData\\Local\\Continuum\\anaconda3\\lib\\pickle.py\", line 856, in save_dict\n    self._batch_setitems(obj.items())\n  File \"C:\\Users\\User\\AppData\\Local\\Continuum\\anaconda3\\lib\\pickle.py\", line 882, in _batch_setitems\n    save(v)\n  File \"C:\\Users\\User\\AppData\\Local\\Continuum\\anaconda3\\lib\\pickle.py\", line 549, in save\n    self.save_reduce(obj=obj, *rv)\n  File \"C:\\Users\\User\\AppData\\Local\\Continuum\\anaconda3\\lib\\pickle.py\", line 662, in save_reduce\n    save(state)\n  File \"C:\\Users\\User\\AppData\\Local\\Continuum\\anaconda3\\lib\\pickle.py\", line 504, in save\n    f(self, obj) # Call unbound method with explicit self\n  File \"C:\\Users\\User\\AppData\\Local\\Continuum\\anaconda3\\lib\\pickle.py\", line 856, in save_dict\n    self._batch_setitems(obj.items())\n  File \"C:\\Users\\User\\AppData\\Local\\Continuum\\anaconda3\\lib\\pickle.py\", line 887, in _batch_setitems\n    save(v)\n  File \"C:\\Users\\User\\AppData\\Local\\Continuum\\anaconda3\\lib\\pickle.py\", line 549, in save\n    self.save_reduce(obj=obj, *rv)\n  File \"C:\\Users\\User\\AppData\\Local\\Continuum\\anaconda3\\lib\\pickle.py\", line 638, in save_reduce\n    save(args)\n  File \"C:\\Users\\User\\AppData\\Local\\Continuum\\anaconda3\\lib\\pickle.py\", line 504, in save\n    f(self, obj) # Call unbound method with explicit self\n  File \"C:\\Users\\User\\AppData\\Local\\Continuum\\anaconda3\\lib\\pickle.py\", line 786, in save_tuple\n    save(element)\n  File \"C:\\Users\\User\\AppData\\Local\\Continuum\\anaconda3\\lib\\pickle.py\", line 504, in save\n    f(self, obj) # Call unbound method with explicit self\n  File \"C:\\Users\\User\\AppData\\Local\\Continuum\\anaconda3\\lib\\pickle.py\", line 816, in save_list\n    self._batch_appends(obj)\n  File \"C:\\Users\\User\\AppData\\Local\\Continuum\\anaconda3\\lib\\pickle.py\", line 843, in _batch_appends\n    save(tmp[0])\n  File \"C:\\Users\\User\\AppData\\Local\\Continuum\\anaconda3\\lib\\pickle.py\", line 504, in save\n    f(self, obj) # Call unbound method with explicit self\n  File \"C:\\Users\\User\\AppData\\Local\\Continuum\\anaconda3\\lib\\pickle.py\", line 771, in save_tuple\n    save(element)\n  File \"C:\\Users\\User\\AppData\\Local\\Continuum\\anaconda3\\lib\\pickle.py\", line 504, in save\n    f(self, obj) # Call unbound method with explicit self\n  File \"C:\\Users\\User\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\joblib\\externals\\cloudpickle\\cloudpickle_fast.py\", line 745, in save_function\n    *self._dynamic_function_reduce(obj), obj=obj\n  File \"C:\\Users\\User\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\joblib\\externals\\cloudpickle\\cloudpickle_fast.py\", line 687, in _save_reduce_pickle5\n    save(state)\n  File \"C:\\Users\\User\\AppData\\Local\\Continuum\\anaconda3\\lib\\pickle.py\", line 504, in save\n    f(self, obj) # Call unbound method with explicit self\n  File \"C:\\Users\\User\\AppData\\Local\\Continuum\\anaconda3\\lib\\pickle.py\", line 771, in save_tuple\n    save(element)\n  File \"C:\\Users\\User\\AppData\\Local\\Continuum\\anaconda3\\lib\\pickle.py\", line 504, in save\n    f(self, obj) # Call unbound method with explicit self\n  File \"C:\\Users\\User\\AppData\\Local\\Continuum\\anaconda3\\lib\\pickle.py\", line 856, in save_dict\n    self._batch_setitems(obj.items())\n  File \"C:\\Users\\User\\AppData\\Local\\Continuum\\anaconda3\\lib\\pickle.py\", line 882, in _batch_setitems\n    save(v)\n  File \"C:\\Users\\User\\AppData\\Local\\Continuum\\anaconda3\\lib\\pickle.py\", line 504, in save\n    f(self, obj) # Call unbound method with explicit self\n  File \"C:\\Users\\User\\AppData\\Local\\Continuum\\anaconda3\\lib\\pickle.py\", line 856, in save_dict\n    self._batch_setitems(obj.items())\n  File \"C:\\Users\\User\\AppData\\Local\\Continuum\\anaconda3\\lib\\pickle.py\", line 887, in _batch_setitems\n    save(v)\n  File \"C:\\Users\\User\\AppData\\Local\\Continuum\\anaconda3\\lib\\pickle.py\", line 549, in save\n    self.save_reduce(obj=obj, *rv)\n  File \"C:\\Users\\User\\AppData\\Local\\Continuum\\anaconda3\\lib\\pickle.py\", line 662, in save_reduce\n    save(state)\n  File \"C:\\Users\\User\\AppData\\Local\\Continuum\\anaconda3\\lib\\pickle.py\", line 504, in save\n    f(self, obj) # Call unbound method with explicit self\n  File \"C:\\Users\\User\\AppData\\Local\\Continuum\\anaconda3\\lib\\pickle.py\", line 856, in save_dict\n    self._batch_setitems(obj.items())\n  File \"C:\\Users\\User\\AppData\\Local\\Continuum\\anaconda3\\lib\\pickle.py\", line 882, in _batch_setitems\n    save(v)\n  File \"C:\\Users\\User\\AppData\\Local\\Continuum\\anaconda3\\lib\\pickle.py\", line 549, in save\n    self.save_reduce(obj=obj, *rv)\n  File \"C:\\Users\\User\\AppData\\Local\\Continuum\\anaconda3\\lib\\pickle.py\", line 662, in save_reduce\n    save(state)\n  File \"C:\\Users\\User\\AppData\\Local\\Continuum\\anaconda3\\lib\\pickle.py\", line 504, in save\n    f(self, obj) # Call unbound method with explicit self\n  File \"C:\\Users\\User\\AppData\\Local\\Continuum\\anaconda3\\lib\\pickle.py\", line 856, in save_dict\n    self._batch_setitems(obj.items())\n  File \"C:\\Users\\User\\AppData\\Local\\Continuum\\anaconda3\\lib\\pickle.py\", line 882, in _batch_setitems\n    save(v)\n  File \"C:\\Users\\User\\AppData\\Local\\Continuum\\anaconda3\\lib\\pickle.py\", line 549, in save\n    self.save_reduce(obj=obj, *rv)\n  File \"C:\\Users\\User\\AppData\\Local\\Continuum\\anaconda3\\lib\\pickle.py\", line 662, in save_reduce\n    save(state)\n  File \"C:\\Users\\User\\AppData\\Local\\Continuum\\anaconda3\\lib\\pickle.py\", line 504, in save\n    f(self, obj) # Call unbound method with explicit self\n  File \"C:\\Users\\User\\AppData\\Local\\Continuum\\anaconda3\\lib\\pickle.py\", line 856, in save_dict\n    self._batch_setitems(obj.items())\n  File \"C:\\Users\\User\\AppData\\Local\\Continuum\\anaconda3\\lib\\pickle.py\", line 882, in _batch_setitems\n    save(v)\n  File \"C:\\Users\\User\\AppData\\Local\\Continuum\\anaconda3\\lib\\pickle.py\", line 504, in save\n    f(self, obj) # Call unbound method with explicit self\n  File \"C:\\Users\\User\\AppData\\Local\\Continuum\\anaconda3\\lib\\pickle.py\", line 856, in save_dict\n    self._batch_setitems(obj.items())\n  File \"C:\\Users\\User\\AppData\\Local\\Continuum\\anaconda3\\lib\\pickle.py\", line 882, in _batch_setitems\n    save(v)\n  File \"C:\\Users\\User\\AppData\\Local\\Continuum\\anaconda3\\lib\\pickle.py\", line 549, in save\n    self.save_reduce(obj=obj, *rv)\n  File \"C:\\Users\\User\\AppData\\Local\\Continuum\\anaconda3\\lib\\pickle.py\", line 662, in save_reduce\n    save(state)\n  File \"C:\\Users\\User\\AppData\\Local\\Continuum\\anaconda3\\lib\\pickle.py\", line 504, in save\n    f(self, obj) # Call unbound method with explicit self\n  File \"C:\\Users\\User\\AppData\\Local\\Continuum\\anaconda3\\lib\\pickle.py\", line 856, in save_dict\n    self._batch_setitems(obj.items())\n  File \"C:\\Users\\User\\AppData\\Local\\Continuum\\anaconda3\\lib\\pickle.py\", line 882, in _batch_setitems\n    save(v)\n  File \"C:\\Users\\User\\AppData\\Local\\Continuum\\anaconda3\\lib\\pickle.py\", line 504, in save\n    f(self, obj) # Call unbound method with explicit self\n  File \"C:\\Users\\User\\AppData\\Local\\Continuum\\anaconda3\\lib\\pickle.py\", line 856, in save_dict\n    self._batch_setitems(obj.items())\n  File \"C:\\Users\\User\\AppData\\Local\\Continuum\\anaconda3\\lib\\pickle.py\", line 882, in _batch_setitems\n    save(v)\n  File \"C:\\Users\\User\\AppData\\Local\\Continuum\\anaconda3\\lib\\pickle.py\", line 524, in save\n    rv = reduce(self.proto)\n  File \"stringsource\", line 2, in zmq.backend.cython.context.Context.__reduce_cython__\nTypeError: no default __reduce__ due to non-trivial __cinit__\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mPicklingError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-d04bb474cea1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdocs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"id\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mParallel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdelayed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeed_datapoint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdocs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1059\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1060\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1061\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1062\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1063\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    938\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    939\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 940\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    941\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    942\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[0;32m    541\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 542\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    543\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    430\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    431\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 432\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    433\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    382\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    383\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 384\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    385\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    386\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mPicklingError\u001b[0m: Could not pickle the task to send it to the workers."
     ]
    }
   ],
   "source": [
    "n = len(docs[\"id\"])\n",
    "print(n)\n",
    "Parallel(n_jobs=2)(delayed(feed_datapoint)(docs.iloc[i,:],i) for i in range(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "Parallel(n_jobs=-1)(delayed(feed_datapoint)(row) for idx, row in docs.iterrows())\n",
    "print(time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "start = time.time()\n",
    "m = start\n",
    "i = 1\n",
    "for idx, row in docs.iterrows():\n",
    "    i += 1\n",
    "    if (i % 100 == 0):\n",
    "        print(i)\n",
    "        print(\"Time:\", round(time.time() - m,1))\n",
    "        m = time.time()\n",
    "    if type(row[\"title\"]) != float:\n",
    "        embedding =  model.encode(row[\"title\"]).tolist()\n",
    "    else:\n",
    "        embedding = [0 for _ in range(768)]\n",
    "    #print(len(row[\"title\"]), end = \"  \")\n",
    "    response = app.feed_data_point(\n",
    "        schema = \"msmarco\",\n",
    "        data_id = str(row[\"id\"]),\n",
    "        fields = {\n",
    "            \"id\": str(row[\"id\"]),\n",
    "            \"title\": str(row[\"title\"]),\n",
    "            \"body\": str(row[\"body\"]),\n",
    "            \"body_length\": len(row[\"body\"]),\n",
    "            \"title_embedding\": embedding\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "num_cores = multiprocessing.cpu_count()\n",
    "print(num_cores)\n",
    "inputs = myList\n",
    "\n",
    "processed_list = Parallel(n_jobs=num_cores)(delayed(my_function(i,parameters) \n",
    "                                                        for i in inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cores = multiprocessing.cpu_count()\n",
    "print(num_cores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numpy_random():\n",
    "    \"\"\"Generate a random number using NumPy\"\"\"\n",
    "    np.random.random(10**7)\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 8*50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = time.time()\n",
    "a = Parallel(n_jobs=-1)(delayed(numpy_random)() for i in range(n))\n",
    "time.time() - s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = time.time()\n",
    "b = [numpy_random() for i in range(n)]\n",
    "time.time() - s     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vespa.query import Query, OR, AND, WeakAnd, ANN, RankProfile as Ranking\n",
    "\n",
    "\n",
    "results = app.query(\n",
    "    query=\"Where is my app\",\n",
    "    query_model = Query(\n",
    "        match_phase=AND(),\n",
    "        rank_profile=Ranking(name=\"default\")\n",
    "    ),\n",
    "    hits = 10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results.request_body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(results.hits)\n",
    "sum = 0\n",
    "for result in results.hits:\n",
    "    sum += result[\"fields\"][\"body_length\"]\n",
    "    print(result[\"id\"], \"  \", result[\"fields\"][\"body_length\"])\n",
    "print(sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Testing different matching phases\n",
    "\n",
    "query_text = \"What is food?\"\n",
    "\n",
    "results1 = app.query(\n",
    "    query=query_text,\n",
    "    query_model = Query(\n",
    "        match_phase=WeakAnd(hits = 1),\n",
    "        rank_profile=Ranking(name=\"default\")\n",
    "    ),\n",
    "    hits = 10\n",
    ")\n",
    "\n",
    "results2 = app.query(\n",
    "    query=query_text,\n",
    "    query_model = Query(\n",
    "        match_phase=OR(),\n",
    "        rank_profile=Ranking(name=\"default\")\n",
    "    ),\n",
    "    hits = 10\n",
    ")\n",
    "\n",
    "results3 = app.query(\n",
    "    query=query_text,\n",
    "    query_model = Query(\n",
    "        match_phase=AND(),\n",
    "        rank_profile=Ranking(name=\"default\")\n",
    "    ),\n",
    "    hits = 10\n",
    ")\n",
    "\n",
    "# Very different number of ducuments retrieved.\n",
    "# \n",
    "print(results1.number_documents_retrieved)\n",
    "print(results2.number_documents_retrieved)\n",
    "print(results3.number_documents_retrieved)\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "# Size of the corpus?\n",
    "print(results1.number_documents_indexed)\n",
    "print(results2.number_documents_indexed)\n",
    "print(results3.number_documents_indexed)\n",
    "\n",
    "#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing WeakAnd\n",
    "# Can be read about here: https://docs.vespa.ai/documentation/using-wand-with-vespa.html\n",
    "# How does hits affect the search?\n",
    "# Is this the target amount of retrived documents?\n",
    "# Retrived documents seam to increase linearly with hits\n",
    "query_text = \"How too kill the warm black friday mood???\"\n",
    "\n",
    "n = 100\n",
    "\n",
    "results = []\n",
    "retrived = np.zeros(n)\n",
    "\n",
    "\n",
    "for i in range(n):\n",
    "    results_temp = app.query(\n",
    "        query=query_text,\n",
    "        query_model = Query(\n",
    "            match_phase=WeakAnd(hits = i),\n",
    "            rank_profile=Ranking(name=\"default\")\n",
    "        ),\n",
    "        hits = 1\n",
    "    )\n",
    "    results.append(results)\n",
    "    retrived[i] = results_temp.number_documents_retrieved\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(retrived)\n",
    "plt.plot(np.arange(100) + retrived[5])\n",
    "plt.ylabel('Numbre of documents retrived')\n",
    "plt.xlabel(\"WeakAnd(hits = x)\")\n",
    "plt.title(\"Query:\" + query_text)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_model = Query(\n",
    "            match_phase=WeakAnd(hits = 10, ),\n",
    "            rank_profile=Ranking(name=\"default\"))\n",
    "    \n",
    "query_model.body\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_package.schema.add_rank_profile(\n",
    "    RankProfile(name = \"body_length\", inherits = \"default\", first_phase = \"body_length\")\n",
    ")\n",
    "\n",
    "path_key = \"C:\\\\Users\\\\User\\\\OneDrive - NTNU\\\\NTNU\\\\Prosjekt oppgave NLP\\\\Cloud_test\\\\\"\n",
    "\n",
    "app = vespa_cloud.deploy(\n",
    "    instance = 'andre-olaisen',\n",
    "    disk_folder = path_key \n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_text = \"Was jesus a socialist\"\n",
    "\n",
    "results_or_default = app.query(\n",
    "    query=query_text,\n",
    "    query_model = Query(\n",
    "        match_phase=OR(),\n",
    "        rank_profile=Ranking(name=\"default\")\n",
    "    ),\n",
    "    hits = 5\n",
    ")\n",
    "\n",
    "results_or_bm25 = app.query(\n",
    "    query=query_text,\n",
    "    query_model = Query(\n",
    "        match_phase=OR(),\n",
    "        rank_profile=Ranking(name=\"bm25\")\n",
    "    ),\n",
    "    hits = 5\n",
    ")\n",
    "\n",
    "print(results_or_default.number_documents_retrieved)\n",
    "print(results_or_bm25.number_documents_retrieved)\n",
    "\n",
    "print(query_text)\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Results: or , deault\")\n",
    "for result in results_or_default.hits:\n",
    "    print(result['fields']['title'])\n",
    "    print(result[\"relevance\"])\n",
    "    \n",
    "print(\"\\n\")\n",
    "    \n",
    "print(\"Results: OR , bm25(title) + bm25(body)\")\n",
    "for result in results_or_bm25.hits:\n",
    "    print(result['fields']['title'])\n",
    "    print(result[\"relevance\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add_rank_profile: What does inherits mean? Why is this needed?\n",
    "# Not able to make bm25 work\n",
    "app_package.schema.add_rank_profile(\n",
    "    RankProfile(name = \"bm25\", inherits = \"default\", first_phase = \"bm25(body)+bm25(title)\")\n",
    ")\n",
    "app_package.schema.add_rank_profile(\n",
    "    RankProfile(name = \"bm25_title\", inherits = \"default\", first_phase = \"bm25(title)\")\n",
    ")\n",
    "app_package.schema.add_rank_profile(\n",
    "    RankProfile(name = \"bm25_body\", inherits = \"default\", first_phase = \"bm25(body)\")\n",
    ")\n",
    "\n",
    "app_package\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After adding a new RankingProfile the app has to be redeployed\n",
    "\n",
    "path_key = \"C:\\\\Users\\\\User\\\\OneDrive - NTNU\\\\NTNU\\\\Prosjekt oppgave NLP\\\\Cloud_test\\\\\"\n",
    "\n",
    "app = vespa_cloud.deploy(\n",
    "    instance='andre-olaisen',\n",
    "    disk_folder=path_key\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_text = \"Could muhammad take a selfie?\"\n",
    "\n",
    "results_or_bm25 = app.query(\n",
    "    query=query_text,\n",
    "    query_model = Query(\n",
    "        match_phase=OR(),\n",
    "        rank_profile=Ranking(name=\"bm25\")\n",
    "    ),\n",
    "    hits = 10\n",
    ")\n",
    "\n",
    "\n",
    "results_or_bm25_title = app.query(\n",
    "    query=query_text,\n",
    "    query_model = Query(\n",
    "        match_phase=OR(),\n",
    "        rank_profile=Ranking(name=\"bm25_body\")\n",
    "    ),\n",
    "    hits = 10\n",
    ")\n",
    "\n",
    "results_or_bm25_body = app.query(\n",
    "    query=query_text,\n",
    "    query_model = Query(\n",
    "        match_phase=OR(),\n",
    "        rank_profile=Ranking(name=\"bm25_title\")\n",
    "    ),\n",
    "    hits = 10\n",
    ")\n",
    "\n",
    "\n",
    "print(\"Results: OR , bm25(title)+bm25(body)\")\n",
    "for result in results_or_bm25.hits:\n",
    "    print(result['fields']['title'])\n",
    "    print(result[\"relevance\"])\n",
    "    \n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Results: OR , bm25(title)\")\n",
    "for result in results_or_bm25_body.hits:\n",
    "    print(result['fields']['title'])\n",
    "    print(result[\"relevance\"])\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"Results: OR , bm25(body)\")\n",
    "for result in results_or_bm25_title.hits:\n",
    "    print(result['fields']['title'])\n",
    "    print(result[\"relevance\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "app_package.schema.add_rank_profile(\n",
    "    RankProfile(name = \"nativerank_bm25_combo\", inherits = \"default\",\n",
    "                first_phase = \"nativeRank(title,body) + bm25(body)\")\n",
    ")\n",
    "\n",
    "# After adding a new RankingProfile the app has to be redeployed\n",
    "\n",
    "path_key = \"C:\\\\Users\\\\User\\\\OneDrive - NTNU\\\\NTNU\\\\Prosjekt oppgave NLP\\\\Cloud_test\\\\\"\n",
    "\n",
    "app = vespa_cloud.deploy(\n",
    "    instance='andre-olaisen',\n",
    "    disk_folder=path_key\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_text = \"Could Muhammad take a selfie?\"\n",
    "\n",
    "results_or_native_bm_combo = app.query(\n",
    "    query=query_text,\n",
    "    query_model = Query(\n",
    "        match_phase=OR(),\n",
    "        rank_profile=Ranking(name=\"nativerank_bm25_combo\")\n",
    "    ),\n",
    "    hits = 10\n",
    ")\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"Results: OR , bm25(body)\")\n",
    "for result in results_or_native_bm_combo.hits:\n",
    "    print(result['fields']['title'])\n",
    "    print(result[\"relevance\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing ANN \n",
    "from vespa.query import Union, WeakAnd, ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "match_phase = Union(\n",
    "    WeakAnd(hits = 10),\n",
    "    ANN(\n",
    "        doc_vector=\"title_embedding\",\n",
    "        query_vector=query_text,\n",
    "        embedding_model=model.encode().tolist(),\n",
    "        hits = 10,\n",
    "        label=\"title\"\n",
    "    )\n",
    ")\n",
    "\n",
    "m\n",
    "\n",
    "rank_profile = Ranking(name=\"default\" ,list_features=True)\n",
    "\n",
    "query_model = Query(match_phase=match_phase, rank_profile=rank_profile)\n",
    "\n",
    "results_ANN_bm25 = app.query(\n",
    "    query=query_text,\n",
    "    query_model = query_model )\n",
    "\n",
    "print(results_ANN_bm25.number_documents_retrieved) # = 0\n",
    "print(results_ANN_bm25.number_documents_indexed)   # = 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "??results_ANN_bm25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_phase.get_query_properties(\"dsfsdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_profile = Ranking(name=\"default\" ,list_features=True)\n",
    "\n",
    "query_model = Query(match_phase=match_phase, rank_profile=rank_profile)\n",
    "\n",
    "results_ANN_bm25 = app.query(\n",
    "    query=query_text,\n",
    "    query_model = query_model)\n",
    "\n",
    "print(results_ANN_bm25.number_documents_retrieved)\n",
    "print(results_ANN_bm25.number_documents_indexed)\n",
    "print(\"\\n\")\n",
    "print(\"Results: ANN , bm25\")\n",
    "for result in results_ANN_bm25.hits:\n",
    "    print(result['fields']['title'])\n",
    "    print(result[\"relevance\"])\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, json\n",
    "\n",
    "labelled_data = json.loads(\n",
    "    requests.get(\"https://thigm85.github.io/data/msmarco/query-labels.json\").text\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(labelled_data))\n",
    "\n",
    "labelled_data[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_ranking = Query(\n",
    "    match_phase=OR(),\n",
    "    rank_profile=Ranking(name=\"default\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25_ranking = Query(\n",
    "    match_phase=OR(),\n",
    "    rank_profile=Ranking(name=\"bm25\")\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vespa.evaluation import MatchRatio, Recall, ReciprocalRank\n",
    "\n",
    "eval_metrics = [MatchRatio(), Recall(at = 10), ReciprocalRank(at = 10)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_evaluation = app.evaluate(\n",
    "    labelled_data=labelled_data,\n",
    "    eval_metrics=eval_metrics,\n",
    "    query_model=default_ranking,\n",
    "    id_field=\"id\",\n",
    "    timeout=5,\n",
    "    hits=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25_evaluation = app.evaluate(\n",
    "    labelled_data=labelled_data,\n",
    "    eval_metrics=eval_metrics,\n",
    "    query_model=bm25_ranking,\n",
    "    id_field=\"id\",\n",
    "    timeout=5,\n",
    "    hits=10\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import merge\n",
    "\n",
    "eval_comparison = merge(\n",
    "    left=default_evaluation,\n",
    "    right=bm25_evaluation,\n",
    "    on=\"query_id\",\n",
    "    suffixes=('_default', '_bm25')\n",
    ")\n",
    "eval_comparison[0:10]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_comparison[[\"match_ratio_value_default\", \"match_ratio_value_bm25\"]].describe().loc[[\"mean\", \"std\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_comparison[[\"recall_10_value_default\", \"recall_10_value_bm25\"]].describe().loc[[\"mean\", \"std\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_comparison[[\"reciprocal_rank_10_value_default\", \"reciprocal_rank_10_value_bm25\"]].describe().loc[[\"mean\", \"std\"]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
