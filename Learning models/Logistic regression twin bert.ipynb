{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import pickle\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>topic_id</th>\n",
       "      <th>round_id</th>\n",
       "      <th>cord_uid</th>\n",
       "      <th>relevancy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.5</td>\n",
       "      <td>005b2j4b</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>00fmeepz</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>010vptx3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0194oljo</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>021q9884</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  topic_id  round_id  cord_uid  relevancy\n",
       "0           0         1       4.5  005b2j4b          2\n",
       "1           1         1       4.0  00fmeepz          1\n",
       "2           2         1       0.5  010vptx3          2\n",
       "3           3         1       2.5  0194oljo          1\n",
       "4           4         1       4.0  021q9884          1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading relevancy data\n",
    "\n",
    "path = 'C:/Users/User/OneDrive - NTNU/NTNU/Prosjekt oppgave NLP/dataset/CORD-19/'\n",
    "file = 'relevance_data.csv'\n",
    "\n",
    "label_data = pd.read_csv(path + file)\n",
    "label_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_id</th>\n",
       "      <th>query</th>\n",
       "      <th>question</th>\n",
       "      <th>narrative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>coronavirus origin</td>\n",
       "      <td>what is the origin of COVID-19</td>\n",
       "      <td>seeking range of information about the SARS-Co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>coronavirus response to weather changes</td>\n",
       "      <td>how does the coronavirus respond to changes in...</td>\n",
       "      <td>seeking range of information about the SARS-Co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>coronavirus immunity</td>\n",
       "      <td>will SARS-CoV2 infected people develop immunit...</td>\n",
       "      <td>seeking studies of immunity developed due to i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>how do people die from the coronavirus</td>\n",
       "      <td>what causes death from Covid-19?</td>\n",
       "      <td>Studies looking at mechanisms of death from Co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>animal models of COVID-19</td>\n",
       "      <td>what drugs have been active against SARS-CoV o...</td>\n",
       "      <td>Papers that describe the results  of testing d...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   query_id                                    query  \\\n",
       "0         1                       coronavirus origin   \n",
       "1         2  coronavirus response to weather changes   \n",
       "2         3                     coronavirus immunity   \n",
       "3         4   how do people die from the coronavirus   \n",
       "4         5                animal models of COVID-19   \n",
       "\n",
       "                                            question  \\\n",
       "0                     what is the origin of COVID-19   \n",
       "1  how does the coronavirus respond to changes in...   \n",
       "2  will SARS-CoV2 infected people develop immunit...   \n",
       "3                   what causes death from Covid-19?   \n",
       "4  what drugs have been active against SARS-CoV o...   \n",
       "\n",
       "                                           narrative  \n",
       "0  seeking range of information about the SARS-Co...  \n",
       "1  seeking range of information about the SARS-Co...  \n",
       "2  seeking studies of immunity developed due to i...  \n",
       "3  Studies looking at mechanisms of death from Co...  \n",
       "4  Papers that describe the results  of testing d...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading topics data\n",
    "\n",
    "path = 'C:/Users/User/OneDrive - NTNU/NTNU/Prosjekt oppgave NLP/dataset/CORD-19/'\n",
    "file = 'topics.csv'\n",
    "\n",
    "topics = pd.read_csv(path + file)\n",
    "topics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69318"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(label_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# available models: ['bert-base-uncased', \"allenai/scibert_scivocab_uncased\", \"gsarti/covidbert-nli\"]\n",
    "\n",
    "def normalize_tensor(tensor):\n",
    "    tensor_normed = []\n",
    "    norm = torch.norm(tensor)\n",
    "    if norm>0:\n",
    "        tensor_normed = tensor/norm\n",
    "    else:\n",
    "        tensor_normed = tensor\n",
    "    return tensor_normed\n",
    "\n",
    "def get_tesors(row, topic_field, doc_field, model):\n",
    "    topic_path = \"C:/Users/User/Documents/NTNU/NLP/CORD-19/topic_embeddings/\"\n",
    "    doc_path = \"C:/Users/User/Documents/NTNU/NLP/CORD-19/Embeddings/786/\"\n",
    "    doc_id = row[\"cord_uid\"]\n",
    "    topic_id = row[\"topic_id\"]\n",
    "    topic_tensor = []\n",
    "    doc_tensor = []\n",
    "    \n",
    "    doc_embedding_file = doc_path + doc_id + \".txt\"\n",
    "    try:\n",
    "        with open(doc_embedding_file, \"rb\") as fp:   # Unpickling\n",
    "            doc_embedding = pickle.load(fp)\n",
    "    except:\n",
    "        return [[0]], [[0]]\n",
    "        \n",
    "    doc_tensor = doc_embedding[\"models\"][model][doc_field]\n",
    "            \n",
    "    topic_embedding_file = topic_path + str(topic_id) + \".txt\"\n",
    "    with open(topic_embedding_file, \"rb\") as fp:   # Unpickling\n",
    "        topic_embedding = pickle.load(fp)\n",
    "        \n",
    "    topic_tensor =  topic_embedding[\"models\"][model][topic_field]\n",
    "    \n",
    "    topic_tensor = normalize_tensor(topic_tensor)\n",
    "    doc_tensor = normalize_tensor(doc_tensor)\n",
    "    \n",
    "    return topic_tensor, doc_tensor\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_tensors(tensor_a,tensor_b):\n",
    "    n = len(tensor_a)\n",
    "    m = len(tensor_b)\n",
    "    c = torch.empty(n + m)\n",
    "    c[0:n] = tensor_a\n",
    "    c[n:(n+m)] = tensor_b\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isNaN(num):\n",
    "    return num != num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-74d7367f3965>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlabel_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0midx\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mnum\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_tesors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"query\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"title\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"allenai/scibert_scivocab_uncased\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m             \u001b[0mc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjoin_tensors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-9639de9b2f62>\u001b[0m in \u001b[0;36mget_tesors\u001b[1;34m(row, topic_field, doc_field, model)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[0mtopic_embedding_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtopic_path\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtopic_id\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\".txt\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtopic_embedding_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m:\u001b[0m   \u001b[1;31m# Unpickling\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m         \u001b[0mtopic_embedding\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num = 2000 # max: 69318\n",
    "x_dataset = torch.empty(num, 768*2)\n",
    "y_dataset = torch.empty(num)\n",
    "miss = 0\n",
    "i = 0\n",
    "for idx, row in label_data.iterrows():\n",
    "    if idx < num:\n",
    "        a, b = get_tesors(row, \"query\", \"title\", \"gsarti/covidbert-nli\")\n",
    "        if len(a[0]) != 1:\n",
    "            c = join_tensors(a[0],b[0])\n",
    "            x_dataset[i] = c\n",
    "        \n",
    "            y_dataset[i] = row[\"relevancy\"]\n",
    "            i+=1\n",
    "        else:\n",
    "            miss +=1\n",
    "print(miss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_dataset = x_dataset[0:(num-miss)]\n",
    "y_dataset = y_dataset[0:(num-miss)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = torch.cat((x_dataset, y_dataset.unsqueeze(1)), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat[1][768*2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(y_dataset))\n",
    "print(len(x_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper Parameters \n",
    "input_size = 768*2\n",
    "num_classes = 3\n",
    "num_epochs = 5\n",
    "batch_size = 1000\n",
    "learning_rate = 0.003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset Loader (Input Pipline)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=dat, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=dat, \n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "class LogisticRegression(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        self.linear = nn.Linear(input_size, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.linear(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(input_size, num_classes)\n",
    "\n",
    "# Loss and Optimizer\n",
    "# Softmax is internally computed.\n",
    "# Set parameters to be updated.\n",
    "criterion = nn.CrossEntropyLoss()  \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "#optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)  \n",
    "\n",
    "# Training the Model\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (X_y) in enumerate(train_loader):\n",
    "        \n",
    "        y = X_y[:,768*2]\n",
    "        #print(y)\n",
    "        X = X_y[:,0:(768*2)].tolist()\n",
    "        #print(X)\n",
    "        #print(list(X.size()))\n",
    "        #print(len(y))\n",
    "        y = y.int()\n",
    "        #print(list(y.size()))\n",
    "        #print(len(y))\n",
    "        y =  torch.LongTensor(y.tolist())\n",
    "        # Forward + Backward + Optimize\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(torch.tensor(X))\n",
    "        loss = criterion(outputs, y)\n",
    "        #print(loss)\n",
    "        #print(model)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1) % 100 == 0:\n",
    "            #print ('Epoch: [%d/%d], Step: [%d/%d], Loss: %.4f' \n",
    "            #       % (epoch+1, num_epochs, i+1, len(train_dataset)//batch_size, loss.data[0]))\n",
    "            print(epoch)\n",
    "            print(loss)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the Model\n",
    "correct = 0\n",
    "total = 0\n",
    "for X_y in test_loader:\n",
    "    y = X_y[:,768*2]\n",
    "    y = y.int()\n",
    "    y =  torch.LongTensor(y.tolist())\n",
    "    #print(y)\n",
    "    X = X_y[:,0:(768*2)].tolist()\n",
    "    X = torch.tensor(X)\n",
    "    outputs = model(X)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += y.size(0)\n",
    "    correct += (predicted == y).sum()\n",
    "    \n",
    "print('Accuracy of the model on the 10000 test images: %d %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_dataset.int().tolist().count(0)/len(y_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "??model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, x in enumerate (x_dataset):\n",
    "    if i < 10:\n",
    "        print(i)\n",
    "        print(len(x))\n",
    "        p = model(x)\n",
    "        print(p)\n",
    "        print(y_dataset[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Hyper Parameters \n",
    "input_size = 784\n",
    "num_classes = 10\n",
    "num_epochs = 5\n",
    "batch_size = 100\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST Dataset (Images and Labels)\n",
    "train_dataset = dsets.MNIST(root='.', \n",
    "                            train=True, \n",
    "                            transform=transforms.ToTensor(),\n",
    "                            download=False)\n",
    "\n",
    "test_dataset = dsets.MNIST(root='.', \n",
    "                           train=False, \n",
    "                           transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_tensor, label = train_dataset[0]\n",
    "print(img_tensor)\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset Loader (Input Pipline)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Model\n",
    "class LogisticRegression(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        self.linear = nn.Linear(input_size, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.linear(x)\n",
    "        return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (images, labels) in enumerate(train_loader):\n",
    "        images = Variable(images.view(-1, 28*28))\n",
    "        labels = Variable(labels)\n",
    "        print(list(dat.size()))\n",
    "        print(images)\n",
    "        print(labels)\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(input_size, num_classes)\n",
    "\n",
    "# Loss and Optimizer\n",
    "# Softmax is internally computed.\n",
    "# Set parameters to be updated.\n",
    "criterion = nn.CrossEntropyLoss()  \n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)  \n",
    "\n",
    "# Training the Model\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = Variable(images.view(-1, 28*28))\n",
    "        labels = Variable(labels)\n",
    "        \n",
    "        #print(labels)\n",
    "        \n",
    "        # Forward + Backward + Optimize\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1) % 100 == 0:\n",
    "            print(images[0])\n",
    "            print(list(images.size()))\n",
    "            print(list(labels.size()))\n",
    "            #print ('Epoch: [%d/%d], Step: [%d/%d], Loss: %.4f' \n",
    "             #      % (epoch+1, num_epochs, i+1, len(train_dataset)//batch_size, loss.data[0]))\n",
    "\n",
    "# Test the Model\n",
    "correct = 0\n",
    "total = 0\n",
    "for images, labels in test_loader:\n",
    "    images = Variable(images.view(-1, 28*28))\n",
    "    outputs = model(images)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum()\n",
    "    \n",
    "print('Accuracy of the model on the 10000 test images: %d %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n",
      "30000\n",
      "31000\n",
      "32000\n",
      "33000\n",
      "34000\n",
      "35000\n",
      "36000\n",
      "37000\n",
      "38000\n",
      "39000\n",
      "40000\n",
      "41000\n",
      "42000\n",
      "43000\n",
      "44000\n",
      "45000\n",
      "46000\n",
      "47000\n",
      "48000\n",
      "49000\n",
      "50000\n",
      "51000\n",
      "52000\n",
      "53000\n",
      "54000\n",
      "55000\n",
      "56000\n",
      "57000\n",
      "58000\n",
      "59000\n",
      "60000\n",
      "61000\n",
      "62000\n",
      "63000\n",
      "64000\n",
      "65000\n",
      "66000\n",
      "67000\n",
      "68000\n",
      "69000\n",
      "1150\n"
     ]
    }
   ],
   "source": [
    "num = 30000 # max: 69318\n",
    "x_dataset = torch.empty(num, 768)\n",
    "y_dataset = torch.empty(num)\n",
    "miss = 0\n",
    "i = 0\n",
    "for idx, row in label_data.iterrows():\n",
    "    if idx < num:\n",
    "        a, b = get_tesors(row, \"query\", \"title\", \"gsarti/covidbert-nli\")\n",
    "        if len(a[0]) != 1:\n",
    "            c = (a[0]*b[0])\n",
    "            x_dataset[i] = c\n",
    "        \n",
    "            y_dataset[i] = row[\"relevancy\"]\n",
    "            i+=1\n",
    "        else:\n",
    "            miss +=1\n",
    "        if idx % 1000 == 0:\n",
    "            print(idx)\n",
    "print(miss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_dataset = x_dataset[0:(num-miss)]\n",
    "y_dataset = y_dataset[0:(num-miss)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = torch.cat((x_dataset, y_dataset.unsqueeze(1)), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper Parameters \n",
    "input_size = 768\n",
    "num_classes = 3\n",
    "num_epochs = 1000\n",
    "batch_size = 1000\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset Loader (Input Pipline)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=dat, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=dat, \n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "class LogisticRegression(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        self.linear = nn.Linear(input_size, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.linear(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0  loss:  tensor(1.1004, grad_fn=<NllLossBackward>)\n",
      "epoch:  0  loss:  tensor(0.9349, grad_fn=<NllLossBackward>)\n",
      "epoch:  10  loss:  tensor(0.8711, grad_fn=<NllLossBackward>)\n",
      "epoch:  10  loss:  tensor(0.8813, grad_fn=<NllLossBackward>)\n",
      "epoch:  20  loss:  tensor(0.8509, grad_fn=<NllLossBackward>)\n",
      "epoch:  20  loss:  tensor(0.8443, grad_fn=<NllLossBackward>)\n",
      "epoch:  30  loss:  tensor(0.8143, grad_fn=<NllLossBackward>)\n",
      "epoch:  30  loss:  tensor(0.8354, grad_fn=<NllLossBackward>)\n",
      "epoch:  40  loss:  tensor(0.8215, grad_fn=<NllLossBackward>)\n",
      "epoch:  40  loss:  tensor(0.8146, grad_fn=<NllLossBackward>)\n",
      "epoch:  50  loss:  tensor(0.8251, grad_fn=<NllLossBackward>)\n",
      "epoch:  50  loss:  tensor(0.7941, grad_fn=<NllLossBackward>)\n",
      "epoch:  60  loss:  tensor(0.8431, grad_fn=<NllLossBackward>)\n",
      "epoch:  60  loss:  tensor(0.8286, grad_fn=<NllLossBackward>)\n",
      "epoch:  70  loss:  tensor(0.8107, grad_fn=<NllLossBackward>)\n",
      "epoch:  70  loss:  tensor(0.8509, grad_fn=<NllLossBackward>)\n",
      "epoch:  80  loss:  tensor(0.8738, grad_fn=<NllLossBackward>)\n",
      "epoch:  80  loss:  tensor(0.8239, grad_fn=<NllLossBackward>)\n",
      "epoch:  90  loss:  tensor(0.8411, grad_fn=<NllLossBackward>)\n",
      "epoch:  90  loss:  tensor(0.8133, grad_fn=<NllLossBackward>)\n",
      "epoch:  100  loss:  tensor(0.8536, grad_fn=<NllLossBackward>)\n",
      "epoch:  100  loss:  tensor(0.7814, grad_fn=<NllLossBackward>)\n",
      "epoch:  110  loss:  tensor(0.8079, grad_fn=<NllLossBackward>)\n",
      "epoch:  110  loss:  tensor(0.7895, grad_fn=<NllLossBackward>)\n",
      "epoch:  120  loss:  tensor(0.8261, grad_fn=<NllLossBackward>)\n",
      "epoch:  120  loss:  tensor(0.7841, grad_fn=<NllLossBackward>)\n",
      "epoch:  130  loss:  tensor(0.7763, grad_fn=<NllLossBackward>)\n",
      "epoch:  130  loss:  tensor(0.8061, grad_fn=<NllLossBackward>)\n",
      "epoch:  140  loss:  tensor(0.8138, grad_fn=<NllLossBackward>)\n",
      "epoch:  140  loss:  tensor(0.7989, grad_fn=<NllLossBackward>)\n",
      "epoch:  150  loss:  tensor(0.7888, grad_fn=<NllLossBackward>)\n",
      "epoch:  150  loss:  tensor(0.7851, grad_fn=<NllLossBackward>)\n",
      "epoch:  160  loss:  tensor(0.7929, grad_fn=<NllLossBackward>)\n",
      "epoch:  160  loss:  tensor(0.8052, grad_fn=<NllLossBackward>)\n",
      "epoch:  170  loss:  tensor(0.8100, grad_fn=<NllLossBackward>)\n",
      "epoch:  170  loss:  tensor(0.8207, grad_fn=<NllLossBackward>)\n",
      "epoch:  180  loss:  tensor(0.7711, grad_fn=<NllLossBackward>)\n",
      "epoch:  180  loss:  tensor(0.7928, grad_fn=<NllLossBackward>)\n",
      "epoch:  190  loss:  tensor(0.7986, grad_fn=<NllLossBackward>)\n",
      "epoch:  190  loss:  tensor(0.8469, grad_fn=<NllLossBackward>)\n",
      "epoch:  200  loss:  tensor(0.8191, grad_fn=<NllLossBackward>)\n",
      "epoch:  200  loss:  tensor(0.7921, grad_fn=<NllLossBackward>)\n",
      "epoch:  210  loss:  tensor(0.8304, grad_fn=<NllLossBackward>)\n",
      "epoch:  210  loss:  tensor(0.7232, grad_fn=<NllLossBackward>)\n",
      "epoch:  220  loss:  tensor(0.7445, grad_fn=<NllLossBackward>)\n",
      "epoch:  220  loss:  tensor(0.7832, grad_fn=<NllLossBackward>)\n",
      "epoch:  230  loss:  tensor(0.8056, grad_fn=<NllLossBackward>)\n",
      "epoch:  230  loss:  tensor(0.7958, grad_fn=<NllLossBackward>)\n",
      "epoch:  240  loss:  tensor(0.7819, grad_fn=<NllLossBackward>)\n",
      "epoch:  240  loss:  tensor(0.7683, grad_fn=<NllLossBackward>)\n",
      "epoch:  250  loss:  tensor(0.7904, grad_fn=<NllLossBackward>)\n",
      "epoch:  250  loss:  tensor(0.7643, grad_fn=<NllLossBackward>)\n",
      "epoch:  260  loss:  tensor(0.7980, grad_fn=<NllLossBackward>)\n",
      "epoch:  260  loss:  tensor(0.7596, grad_fn=<NllLossBackward>)\n",
      "epoch:  270  loss:  tensor(0.7880, grad_fn=<NllLossBackward>)\n",
      "epoch:  270  loss:  tensor(0.7766, grad_fn=<NllLossBackward>)\n",
      "epoch:  280  loss:  tensor(0.7953, grad_fn=<NllLossBackward>)\n",
      "epoch:  280  loss:  tensor(0.7957, grad_fn=<NllLossBackward>)\n",
      "epoch:  290  loss:  tensor(0.7870, grad_fn=<NllLossBackward>)\n",
      "epoch:  290  loss:  tensor(0.7658, grad_fn=<NllLossBackward>)\n",
      "epoch:  300  loss:  tensor(0.7683, grad_fn=<NllLossBackward>)\n",
      "epoch:  300  loss:  tensor(0.7664, grad_fn=<NllLossBackward>)\n",
      "epoch:  310  loss:  tensor(0.7683, grad_fn=<NllLossBackward>)\n",
      "epoch:  310  loss:  tensor(0.7840, grad_fn=<NllLossBackward>)\n",
      "epoch:  320  loss:  tensor(0.7293, grad_fn=<NllLossBackward>)\n",
      "epoch:  320  loss:  tensor(0.7868, grad_fn=<NllLossBackward>)\n",
      "epoch:  330  loss:  tensor(0.7679, grad_fn=<NllLossBackward>)\n",
      "epoch:  330  loss:  tensor(0.8082, grad_fn=<NllLossBackward>)\n",
      "epoch:  340  loss:  tensor(0.7632, grad_fn=<NllLossBackward>)\n",
      "epoch:  340  loss:  tensor(0.7519, grad_fn=<NllLossBackward>)\n",
      "epoch:  350  loss:  tensor(0.7870, grad_fn=<NllLossBackward>)\n",
      "epoch:  350  loss:  tensor(0.7636, grad_fn=<NllLossBackward>)\n",
      "epoch:  360  loss:  tensor(0.7959, grad_fn=<NllLossBackward>)\n",
      "epoch:  360  loss:  tensor(0.7856, grad_fn=<NllLossBackward>)\n",
      "epoch:  370  loss:  tensor(0.7825, grad_fn=<NllLossBackward>)\n",
      "epoch:  370  loss:  tensor(0.7873, grad_fn=<NllLossBackward>)\n",
      "epoch:  380  loss:  tensor(0.7819, grad_fn=<NllLossBackward>)\n",
      "epoch:  380  loss:  tensor(0.7882, grad_fn=<NllLossBackward>)\n",
      "epoch:  390  loss:  tensor(0.7749, grad_fn=<NllLossBackward>)\n",
      "epoch:  390  loss:  tensor(0.7855, grad_fn=<NllLossBackward>)\n",
      "epoch:  400  loss:  tensor(0.7592, grad_fn=<NllLossBackward>)\n",
      "epoch:  400  loss:  tensor(0.7457, grad_fn=<NllLossBackward>)\n",
      "epoch:  410  loss:  tensor(0.7976, grad_fn=<NllLossBackward>)\n",
      "epoch:  410  loss:  tensor(0.7577, grad_fn=<NllLossBackward>)\n",
      "epoch:  420  loss:  tensor(0.7607, grad_fn=<NllLossBackward>)\n",
      "epoch:  420  loss:  tensor(0.7611, grad_fn=<NllLossBackward>)\n",
      "epoch:  430  loss:  tensor(0.7579, grad_fn=<NllLossBackward>)\n",
      "epoch:  430  loss:  tensor(0.8097, grad_fn=<NllLossBackward>)\n",
      "epoch:  440  loss:  tensor(0.7268, grad_fn=<NllLossBackward>)\n",
      "epoch:  440  loss:  tensor(0.7934, grad_fn=<NllLossBackward>)\n",
      "epoch:  450  loss:  tensor(0.7535, grad_fn=<NllLossBackward>)\n",
      "epoch:  450  loss:  tensor(0.7658, grad_fn=<NllLossBackward>)\n",
      "epoch:  460  loss:  tensor(0.7400, grad_fn=<NllLossBackward>)\n",
      "epoch:  460  loss:  tensor(0.7581, grad_fn=<NllLossBackward>)\n",
      "epoch:  470  loss:  tensor(0.7726, grad_fn=<NllLossBackward>)\n",
      "epoch:  470  loss:  tensor(0.7411, grad_fn=<NllLossBackward>)\n",
      "epoch:  480  loss:  tensor(0.7793, grad_fn=<NllLossBackward>)\n",
      "epoch:  480  loss:  tensor(0.7734, grad_fn=<NllLossBackward>)\n",
      "epoch:  490  loss:  tensor(0.7746, grad_fn=<NllLossBackward>)\n",
      "epoch:  490  loss:  tensor(0.7396, grad_fn=<NllLossBackward>)\n",
      "epoch:  500  loss:  tensor(0.7863, grad_fn=<NllLossBackward>)\n",
      "epoch:  500  loss:  tensor(0.7379, grad_fn=<NllLossBackward>)\n",
      "epoch:  510  loss:  tensor(0.7476, grad_fn=<NllLossBackward>)\n",
      "epoch:  510  loss:  tensor(0.7739, grad_fn=<NllLossBackward>)\n",
      "epoch:  520  loss:  tensor(0.7494, grad_fn=<NllLossBackward>)\n",
      "epoch:  520  loss:  tensor(0.7747, grad_fn=<NllLossBackward>)\n",
      "epoch:  530  loss:  tensor(0.7422, grad_fn=<NllLossBackward>)\n",
      "epoch:  530  loss:  tensor(0.7379, grad_fn=<NllLossBackward>)\n",
      "epoch:  540  loss:  tensor(0.7590, grad_fn=<NllLossBackward>)\n",
      "epoch:  540  loss:  tensor(0.7226, grad_fn=<NllLossBackward>)\n",
      "epoch:  550  loss:  tensor(0.7563, grad_fn=<NllLossBackward>)\n",
      "epoch:  550  loss:  tensor(0.7562, grad_fn=<NllLossBackward>)\n",
      "epoch:  560  loss:  tensor(0.7615, grad_fn=<NllLossBackward>)\n",
      "epoch:  560  loss:  tensor(0.7439, grad_fn=<NllLossBackward>)\n",
      "epoch:  570  loss:  tensor(0.8002, grad_fn=<NllLossBackward>)\n",
      "epoch:  570  loss:  tensor(0.7508, grad_fn=<NllLossBackward>)\n",
      "epoch:  580  loss:  tensor(0.8114, grad_fn=<NllLossBackward>)\n",
      "epoch:  580  loss:  tensor(0.7752, grad_fn=<NllLossBackward>)\n",
      "epoch:  590  loss:  tensor(0.7409, grad_fn=<NllLossBackward>)\n",
      "epoch:  590  loss:  tensor(0.7430, grad_fn=<NllLossBackward>)\n",
      "epoch:  600  loss:  tensor(0.7655, grad_fn=<NllLossBackward>)\n",
      "epoch:  600  loss:  tensor(0.7595, grad_fn=<NllLossBackward>)\n",
      "epoch:  610  loss:  tensor(0.7711, grad_fn=<NllLossBackward>)\n",
      "epoch:  610  loss:  tensor(0.7431, grad_fn=<NllLossBackward>)\n",
      "epoch:  620  loss:  tensor(0.7387, grad_fn=<NllLossBackward>)\n",
      "epoch:  620  loss:  tensor(0.7439, grad_fn=<NllLossBackward>)\n",
      "epoch:  630  loss:  tensor(0.7118, grad_fn=<NllLossBackward>)\n",
      "epoch:  630  loss:  tensor(0.7599, grad_fn=<NllLossBackward>)\n",
      "epoch:  640  loss:  tensor(0.7067, grad_fn=<NllLossBackward>)\n",
      "epoch:  640  loss:  tensor(0.7649, grad_fn=<NllLossBackward>)\n",
      "epoch:  650  loss:  tensor(0.7272, grad_fn=<NllLossBackward>)\n",
      "epoch:  650  loss:  tensor(0.7644, grad_fn=<NllLossBackward>)\n",
      "epoch:  660  loss:  tensor(0.7837, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  660  loss:  tensor(0.7735, grad_fn=<NllLossBackward>)\n",
      "epoch:  670  loss:  tensor(0.7522, grad_fn=<NllLossBackward>)\n",
      "epoch:  670  loss:  tensor(0.7325, grad_fn=<NllLossBackward>)\n",
      "epoch:  680  loss:  tensor(0.7784, grad_fn=<NllLossBackward>)\n",
      "epoch:  680  loss:  tensor(0.7205, grad_fn=<NllLossBackward>)\n",
      "epoch:  690  loss:  tensor(0.7695, grad_fn=<NllLossBackward>)\n",
      "epoch:  690  loss:  tensor(0.7436, grad_fn=<NllLossBackward>)\n",
      "epoch:  700  loss:  tensor(0.7082, grad_fn=<NllLossBackward>)\n",
      "epoch:  700  loss:  tensor(0.7337, grad_fn=<NllLossBackward>)\n",
      "epoch:  710  loss:  tensor(0.7570, grad_fn=<NllLossBackward>)\n",
      "epoch:  710  loss:  tensor(0.8014, grad_fn=<NllLossBackward>)\n",
      "epoch:  720  loss:  tensor(0.7442, grad_fn=<NllLossBackward>)\n",
      "epoch:  720  loss:  tensor(0.7415, grad_fn=<NllLossBackward>)\n",
      "epoch:  730  loss:  tensor(0.7511, grad_fn=<NllLossBackward>)\n",
      "epoch:  730  loss:  tensor(0.7460, grad_fn=<NllLossBackward>)\n",
      "epoch:  740  loss:  tensor(0.7068, grad_fn=<NllLossBackward>)\n",
      "epoch:  740  loss:  tensor(0.7415, grad_fn=<NllLossBackward>)\n",
      "epoch:  750  loss:  tensor(0.7343, grad_fn=<NllLossBackward>)\n",
      "epoch:  750  loss:  tensor(0.7526, grad_fn=<NllLossBackward>)\n",
      "epoch:  760  loss:  tensor(0.7328, grad_fn=<NllLossBackward>)\n",
      "epoch:  760  loss:  tensor(0.7374, grad_fn=<NllLossBackward>)\n",
      "epoch:  770  loss:  tensor(0.7310, grad_fn=<NllLossBackward>)\n",
      "epoch:  770  loss:  tensor(0.7608, grad_fn=<NllLossBackward>)\n",
      "epoch:  780  loss:  tensor(0.7498, grad_fn=<NllLossBackward>)\n",
      "epoch:  780  loss:  tensor(0.7266, grad_fn=<NllLossBackward>)\n",
      "epoch:  790  loss:  tensor(0.7813, grad_fn=<NllLossBackward>)\n",
      "epoch:  790  loss:  tensor(0.7380, grad_fn=<NllLossBackward>)\n",
      "epoch:  800  loss:  tensor(0.7384, grad_fn=<NllLossBackward>)\n",
      "epoch:  800  loss:  tensor(0.7205, grad_fn=<NllLossBackward>)\n",
      "epoch:  810  loss:  tensor(0.7645, grad_fn=<NllLossBackward>)\n",
      "epoch:  810  loss:  tensor(0.7286, grad_fn=<NllLossBackward>)\n",
      "epoch:  820  loss:  tensor(0.7704, grad_fn=<NllLossBackward>)\n",
      "epoch:  820  loss:  tensor(0.7576, grad_fn=<NllLossBackward>)\n",
      "epoch:  830  loss:  tensor(0.7420, grad_fn=<NllLossBackward>)\n",
      "epoch:  830  loss:  tensor(0.7145, grad_fn=<NllLossBackward>)\n",
      "epoch:  840  loss:  tensor(0.7404, grad_fn=<NllLossBackward>)\n",
      "epoch:  840  loss:  tensor(0.7320, grad_fn=<NllLossBackward>)\n",
      "epoch:  850  loss:  tensor(0.7684, grad_fn=<NllLossBackward>)\n",
      "epoch:  850  loss:  tensor(0.7558, grad_fn=<NllLossBackward>)\n",
      "epoch:  860  loss:  tensor(0.7318, grad_fn=<NllLossBackward>)\n",
      "epoch:  860  loss:  tensor(0.7585, grad_fn=<NllLossBackward>)\n",
      "epoch:  870  loss:  tensor(0.7607, grad_fn=<NllLossBackward>)\n",
      "epoch:  870  loss:  tensor(0.7587, grad_fn=<NllLossBackward>)\n",
      "epoch:  880  loss:  tensor(0.7395, grad_fn=<NllLossBackward>)\n",
      "epoch:  880  loss:  tensor(0.7166, grad_fn=<NllLossBackward>)\n",
      "epoch:  890  loss:  tensor(0.7166, grad_fn=<NllLossBackward>)\n",
      "epoch:  890  loss:  tensor(0.7275, grad_fn=<NllLossBackward>)\n",
      "epoch:  900  loss:  tensor(0.7322, grad_fn=<NllLossBackward>)\n",
      "epoch:  900  loss:  tensor(0.7203, grad_fn=<NllLossBackward>)\n",
      "epoch:  910  loss:  tensor(0.7016, grad_fn=<NllLossBackward>)\n",
      "epoch:  910  loss:  tensor(0.7499, grad_fn=<NllLossBackward>)\n",
      "epoch:  920  loss:  tensor(0.7269, grad_fn=<NllLossBackward>)\n",
      "epoch:  920  loss:  tensor(0.7099, grad_fn=<NllLossBackward>)\n",
      "epoch:  930  loss:  tensor(0.7418, grad_fn=<NllLossBackward>)\n",
      "epoch:  930  loss:  tensor(0.7310, grad_fn=<NllLossBackward>)\n",
      "epoch:  940  loss:  tensor(0.7379, grad_fn=<NllLossBackward>)\n",
      "epoch:  940  loss:  tensor(0.7363, grad_fn=<NllLossBackward>)\n",
      "epoch:  950  loss:  tensor(0.7026, grad_fn=<NllLossBackward>)\n",
      "epoch:  950  loss:  tensor(0.7248, grad_fn=<NllLossBackward>)\n",
      "epoch:  960  loss:  tensor(0.7674, grad_fn=<NllLossBackward>)\n",
      "epoch:  960  loss:  tensor(0.7153, grad_fn=<NllLossBackward>)\n",
      "epoch:  970  loss:  tensor(0.7629, grad_fn=<NllLossBackward>)\n",
      "epoch:  970  loss:  tensor(0.7049, grad_fn=<NllLossBackward>)\n",
      "epoch:  980  loss:  tensor(0.7172, grad_fn=<NllLossBackward>)\n",
      "epoch:  980  loss:  tensor(0.7232, grad_fn=<NllLossBackward>)\n",
      "epoch:  990  loss:  tensor(0.7396, grad_fn=<NllLossBackward>)\n",
      "epoch:  990  loss:  tensor(0.7475, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(input_size, num_classes)\n",
    "\n",
    "# Loss and Optimizer\n",
    "# Softmax is internally computed.\n",
    "# Set parameters to be updated.\n",
    "criterion = nn.CrossEntropyLoss()  \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "#optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)  \n",
    "\n",
    "loss_list = []\n",
    "# Training the Model\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (X_y) in enumerate(train_loader):\n",
    "        \n",
    "        y = X_y[:,768]\n",
    "        #print(y)\n",
    "        X = X_y[:,0:(768)]#.tolist()\n",
    "        \n",
    "        #print(X)\n",
    "        #print(list(X.size()))\n",
    "        #print(len(y))\n",
    "        y = y.int()\n",
    "        #print(list(y.size()))\n",
    "        #print(len(y))\n",
    "        y =  torch.LongTensor(y.tolist())\n",
    "        #print(y)\n",
    "        # Forward + Backward + Optimize\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(torch.tensor(X))\n",
    "        loss = criterion(outputs, y)\n",
    "        #print(loss)\n",
    "        #print(model)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        loss_list.append(loss)\n",
    "        \n",
    "        if ((i) % 20 == 0) and (epoch % 10 == 0):\n",
    "            #print ('Epoch: [%d/%d], Step: [%d/%d], Loss: %.4f' \n",
    "            #       % (epoch+1, num_epochs, i+1, len(train_dataset)//batch_size, loss.data[0]))\n",
    "            print(\"epoch: \",  epoch, \" loss: \", loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:23: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0  loss:  tensor(0.6967, grad_fn=<NllLossBackward>)\n",
      "epoch:  0  loss:  tensor(0.7091, grad_fn=<NllLossBackward>)\n",
      "epoch:  10  loss:  tensor(0.7450, grad_fn=<NllLossBackward>)\n",
      "epoch:  10  loss:  tensor(0.7240, grad_fn=<NllLossBackward>)\n",
      "epoch:  20  loss:  tensor(0.7550, grad_fn=<NllLossBackward>)\n",
      "epoch:  20  loss:  tensor(0.7457, grad_fn=<NllLossBackward>)\n",
      "epoch:  30  loss:  tensor(0.7701, grad_fn=<NllLossBackward>)\n",
      "epoch:  30  loss:  tensor(0.7332, grad_fn=<NllLossBackward>)\n",
      "epoch:  40  loss:  tensor(0.7464, grad_fn=<NllLossBackward>)\n",
      "epoch:  40  loss:  tensor(0.7245, grad_fn=<NllLossBackward>)\n",
      "epoch:  50  loss:  tensor(0.7182, grad_fn=<NllLossBackward>)\n",
      "epoch:  50  loss:  tensor(0.7123, grad_fn=<NllLossBackward>)\n",
      "epoch:  60  loss:  tensor(0.7168, grad_fn=<NllLossBackward>)\n",
      "epoch:  60  loss:  tensor(0.7164, grad_fn=<NllLossBackward>)\n",
      "epoch:  70  loss:  tensor(0.7724, grad_fn=<NllLossBackward>)\n",
      "epoch:  70  loss:  tensor(0.7141, grad_fn=<NllLossBackward>)\n",
      "epoch:  80  loss:  tensor(0.6971, grad_fn=<NllLossBackward>)\n",
      "epoch:  80  loss:  tensor(0.7655, grad_fn=<NllLossBackward>)\n",
      "epoch:  90  loss:  tensor(0.7505, grad_fn=<NllLossBackward>)\n",
      "epoch:  90  loss:  tensor(0.7681, grad_fn=<NllLossBackward>)\n",
      "epoch:  100  loss:  tensor(0.7309, grad_fn=<NllLossBackward>)\n",
      "epoch:  100  loss:  tensor(0.7305, grad_fn=<NllLossBackward>)\n",
      "epoch:  110  loss:  tensor(0.7174, grad_fn=<NllLossBackward>)\n",
      "epoch:  110  loss:  tensor(0.7415, grad_fn=<NllLossBackward>)\n",
      "epoch:  120  loss:  tensor(0.7186, grad_fn=<NllLossBackward>)\n",
      "epoch:  120  loss:  tensor(0.7635, grad_fn=<NllLossBackward>)\n",
      "epoch:  130  loss:  tensor(0.7479, grad_fn=<NllLossBackward>)\n",
      "epoch:  130  loss:  tensor(0.7495, grad_fn=<NllLossBackward>)\n",
      "epoch:  140  loss:  tensor(0.7799, grad_fn=<NllLossBackward>)\n",
      "epoch:  140  loss:  tensor(0.7438, grad_fn=<NllLossBackward>)\n",
      "epoch:  150  loss:  tensor(0.7629, grad_fn=<NllLossBackward>)\n",
      "epoch:  150  loss:  tensor(0.7181, grad_fn=<NllLossBackward>)\n",
      "epoch:  160  loss:  tensor(0.7304, grad_fn=<NllLossBackward>)\n",
      "epoch:  160  loss:  tensor(0.7602, grad_fn=<NllLossBackward>)\n",
      "epoch:  170  loss:  tensor(0.7044, grad_fn=<NllLossBackward>)\n",
      "epoch:  170  loss:  tensor(0.7760, grad_fn=<NllLossBackward>)\n",
      "epoch:  180  loss:  tensor(0.7227, grad_fn=<NllLossBackward>)\n",
      "epoch:  180  loss:  tensor(0.7189, grad_fn=<NllLossBackward>)\n",
      "epoch:  190  loss:  tensor(0.7172, grad_fn=<NllLossBackward>)\n",
      "epoch:  190  loss:  tensor(0.7188, grad_fn=<NllLossBackward>)\n",
      "epoch:  200  loss:  tensor(0.7302, grad_fn=<NllLossBackward>)\n",
      "epoch:  200  loss:  tensor(0.7552, grad_fn=<NllLossBackward>)\n",
      "epoch:  210  loss:  tensor(0.7194, grad_fn=<NllLossBackward>)\n",
      "epoch:  210  loss:  tensor(0.7591, grad_fn=<NllLossBackward>)\n",
      "epoch:  220  loss:  tensor(0.7558, grad_fn=<NllLossBackward>)\n",
      "epoch:  220  loss:  tensor(0.7315, grad_fn=<NllLossBackward>)\n",
      "epoch:  230  loss:  tensor(0.7504, grad_fn=<NllLossBackward>)\n",
      "epoch:  230  loss:  tensor(0.7240, grad_fn=<NllLossBackward>)\n",
      "epoch:  240  loss:  tensor(0.7365, grad_fn=<NllLossBackward>)\n",
      "epoch:  240  loss:  tensor(0.7223, grad_fn=<NllLossBackward>)\n",
      "epoch:  250  loss:  tensor(0.7615, grad_fn=<NllLossBackward>)\n",
      "epoch:  250  loss:  tensor(0.6986, grad_fn=<NllLossBackward>)\n",
      "epoch:  260  loss:  tensor(0.7390, grad_fn=<NllLossBackward>)\n",
      "epoch:  260  loss:  tensor(0.7595, grad_fn=<NllLossBackward>)\n",
      "epoch:  270  loss:  tensor(0.7604, grad_fn=<NllLossBackward>)\n",
      "epoch:  270  loss:  tensor(0.7572, grad_fn=<NllLossBackward>)\n",
      "epoch:  280  loss:  tensor(0.7208, grad_fn=<NllLossBackward>)\n",
      "epoch:  280  loss:  tensor(0.7199, grad_fn=<NllLossBackward>)\n",
      "epoch:  290  loss:  tensor(0.7413, grad_fn=<NllLossBackward>)\n",
      "epoch:  290  loss:  tensor(0.7035, grad_fn=<NllLossBackward>)\n",
      "epoch:  300  loss:  tensor(0.7710, grad_fn=<NllLossBackward>)\n",
      "epoch:  300  loss:  tensor(0.7461, grad_fn=<NllLossBackward>)\n",
      "epoch:  310  loss:  tensor(0.7417, grad_fn=<NllLossBackward>)\n",
      "epoch:  310  loss:  tensor(0.7631, grad_fn=<NllLossBackward>)\n",
      "epoch:  320  loss:  tensor(0.7457, grad_fn=<NllLossBackward>)\n",
      "epoch:  320  loss:  tensor(0.7400, grad_fn=<NllLossBackward>)\n",
      "epoch:  330  loss:  tensor(0.7522, grad_fn=<NllLossBackward>)\n",
      "epoch:  330  loss:  tensor(0.7266, grad_fn=<NllLossBackward>)\n",
      "epoch:  340  loss:  tensor(0.7477, grad_fn=<NllLossBackward>)\n",
      "epoch:  340  loss:  tensor(0.7543, grad_fn=<NllLossBackward>)\n",
      "epoch:  350  loss:  tensor(0.7421, grad_fn=<NllLossBackward>)\n",
      "epoch:  350  loss:  tensor(0.7819, grad_fn=<NllLossBackward>)\n",
      "epoch:  360  loss:  tensor(0.6971, grad_fn=<NllLossBackward>)\n",
      "epoch:  360  loss:  tensor(0.7287, grad_fn=<NllLossBackward>)\n",
      "epoch:  370  loss:  tensor(0.7288, grad_fn=<NllLossBackward>)\n",
      "epoch:  370  loss:  tensor(0.7376, grad_fn=<NllLossBackward>)\n",
      "epoch:  380  loss:  tensor(0.7032, grad_fn=<NllLossBackward>)\n",
      "epoch:  380  loss:  tensor(0.7721, grad_fn=<NllLossBackward>)\n",
      "epoch:  390  loss:  tensor(0.7355, grad_fn=<NllLossBackward>)\n",
      "epoch:  390  loss:  tensor(0.7237, grad_fn=<NllLossBackward>)\n",
      "epoch:  400  loss:  tensor(0.6982, grad_fn=<NllLossBackward>)\n",
      "epoch:  400  loss:  tensor(0.7643, grad_fn=<NllLossBackward>)\n",
      "epoch:  410  loss:  tensor(0.7808, grad_fn=<NllLossBackward>)\n",
      "epoch:  410  loss:  tensor(0.7630, grad_fn=<NllLossBackward>)\n",
      "epoch:  420  loss:  tensor(0.7337, grad_fn=<NllLossBackward>)\n",
      "epoch:  420  loss:  tensor(0.7276, grad_fn=<NllLossBackward>)\n",
      "epoch:  430  loss:  tensor(0.7514, grad_fn=<NllLossBackward>)\n",
      "epoch:  430  loss:  tensor(0.7368, grad_fn=<NllLossBackward>)\n",
      "epoch:  440  loss:  tensor(0.7058, grad_fn=<NllLossBackward>)\n",
      "epoch:  440  loss:  tensor(0.7420, grad_fn=<NllLossBackward>)\n",
      "epoch:  450  loss:  tensor(0.6861, grad_fn=<NllLossBackward>)\n",
      "epoch:  450  loss:  tensor(0.7465, grad_fn=<NllLossBackward>)\n",
      "epoch:  460  loss:  tensor(0.7047, grad_fn=<NllLossBackward>)\n",
      "epoch:  460  loss:  tensor(0.7826, grad_fn=<NllLossBackward>)\n",
      "epoch:  470  loss:  tensor(0.7570, grad_fn=<NllLossBackward>)\n",
      "epoch:  470  loss:  tensor(0.7223, grad_fn=<NllLossBackward>)\n",
      "epoch:  480  loss:  tensor(0.7457, grad_fn=<NllLossBackward>)\n",
      "epoch:  480  loss:  tensor(0.7229, grad_fn=<NllLossBackward>)\n",
      "epoch:  490  loss:  tensor(0.7298, grad_fn=<NllLossBackward>)\n",
      "epoch:  490  loss:  tensor(0.7480, grad_fn=<NllLossBackward>)\n",
      "epoch:  500  loss:  tensor(0.7431, grad_fn=<NllLossBackward>)\n",
      "epoch:  500  loss:  tensor(0.7350, grad_fn=<NllLossBackward>)\n",
      "epoch:  510  loss:  tensor(0.7634, grad_fn=<NllLossBackward>)\n",
      "epoch:  510  loss:  tensor(0.7155, grad_fn=<NllLossBackward>)\n",
      "epoch:  520  loss:  tensor(0.7469, grad_fn=<NllLossBackward>)\n",
      "epoch:  520  loss:  tensor(0.7441, grad_fn=<NllLossBackward>)\n",
      "epoch:  530  loss:  tensor(0.7324, grad_fn=<NllLossBackward>)\n",
      "epoch:  530  loss:  tensor(0.7631, grad_fn=<NllLossBackward>)\n",
      "epoch:  540  loss:  tensor(0.7325, grad_fn=<NllLossBackward>)\n",
      "epoch:  540  loss:  tensor(0.7640, grad_fn=<NllLossBackward>)\n",
      "epoch:  550  loss:  tensor(0.7016, grad_fn=<NllLossBackward>)\n",
      "epoch:  550  loss:  tensor(0.7418, grad_fn=<NllLossBackward>)\n",
      "epoch:  560  loss:  tensor(0.7514, grad_fn=<NllLossBackward>)\n",
      "epoch:  560  loss:  tensor(0.7136, grad_fn=<NllLossBackward>)\n",
      "epoch:  570  loss:  tensor(0.7219, grad_fn=<NllLossBackward>)\n",
      "epoch:  570  loss:  tensor(0.7521, grad_fn=<NllLossBackward>)\n",
      "epoch:  580  loss:  tensor(0.7279, grad_fn=<NllLossBackward>)\n",
      "epoch:  580  loss:  tensor(0.7206, grad_fn=<NllLossBackward>)\n",
      "epoch:  590  loss:  tensor(0.7708, grad_fn=<NllLossBackward>)\n",
      "epoch:  590  loss:  tensor(0.7165, grad_fn=<NllLossBackward>)\n",
      "epoch:  600  loss:  tensor(0.7639, grad_fn=<NllLossBackward>)\n",
      "epoch:  600  loss:  tensor(0.7486, grad_fn=<NllLossBackward>)\n",
      "epoch:  610  loss:  tensor(0.7403, grad_fn=<NllLossBackward>)\n",
      "epoch:  610  loss:  tensor(0.7162, grad_fn=<NllLossBackward>)\n",
      "epoch:  620  loss:  tensor(0.7591, grad_fn=<NllLossBackward>)\n",
      "epoch:  620  loss:  tensor(0.7689, grad_fn=<NllLossBackward>)\n",
      "epoch:  630  loss:  tensor(0.7585, grad_fn=<NllLossBackward>)\n",
      "epoch:  630  loss:  tensor(0.7421, grad_fn=<NllLossBackward>)\n",
      "epoch:  640  loss:  tensor(0.7522, grad_fn=<NllLossBackward>)\n",
      "epoch:  640  loss:  tensor(0.7490, grad_fn=<NllLossBackward>)\n",
      "epoch:  650  loss:  tensor(0.7589, grad_fn=<NllLossBackward>)\n",
      "epoch:  650  loss:  tensor(0.7332, grad_fn=<NllLossBackward>)\n",
      "epoch:  660  loss:  tensor(0.7527, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  660  loss:  tensor(0.7510, grad_fn=<NllLossBackward>)\n",
      "epoch:  670  loss:  tensor(0.7311, grad_fn=<NllLossBackward>)\n",
      "epoch:  670  loss:  tensor(0.7479, grad_fn=<NllLossBackward>)\n",
      "epoch:  680  loss:  tensor(0.7509, grad_fn=<NllLossBackward>)\n",
      "epoch:  680  loss:  tensor(0.7127, grad_fn=<NllLossBackward>)\n",
      "epoch:  690  loss:  tensor(0.7368, grad_fn=<NllLossBackward>)\n",
      "epoch:  690  loss:  tensor(0.7405, grad_fn=<NllLossBackward>)\n",
      "epoch:  700  loss:  tensor(0.7556, grad_fn=<NllLossBackward>)\n",
      "epoch:  700  loss:  tensor(0.7532, grad_fn=<NllLossBackward>)\n",
      "epoch:  710  loss:  tensor(0.7305, grad_fn=<NllLossBackward>)\n",
      "epoch:  710  loss:  tensor(0.7321, grad_fn=<NllLossBackward>)\n",
      "epoch:  720  loss:  tensor(0.7160, grad_fn=<NllLossBackward>)\n",
      "epoch:  720  loss:  tensor(0.6950, grad_fn=<NllLossBackward>)\n",
      "epoch:  730  loss:  tensor(0.7482, grad_fn=<NllLossBackward>)\n",
      "epoch:  730  loss:  tensor(0.7336, grad_fn=<NllLossBackward>)\n",
      "epoch:  740  loss:  tensor(0.7655, grad_fn=<NllLossBackward>)\n",
      "epoch:  740  loss:  tensor(0.7371, grad_fn=<NllLossBackward>)\n",
      "epoch:  750  loss:  tensor(0.7476, grad_fn=<NllLossBackward>)\n",
      "epoch:  750  loss:  tensor(0.7298, grad_fn=<NllLossBackward>)\n",
      "epoch:  760  loss:  tensor(0.7556, grad_fn=<NllLossBackward>)\n",
      "epoch:  760  loss:  tensor(0.6976, grad_fn=<NllLossBackward>)\n",
      "epoch:  770  loss:  tensor(0.7297, grad_fn=<NllLossBackward>)\n",
      "epoch:  770  loss:  tensor(0.7333, grad_fn=<NllLossBackward>)\n",
      "epoch:  780  loss:  tensor(0.7437, grad_fn=<NllLossBackward>)\n",
      "epoch:  780  loss:  tensor(0.7232, grad_fn=<NllLossBackward>)\n",
      "epoch:  790  loss:  tensor(0.7532, grad_fn=<NllLossBackward>)\n",
      "epoch:  790  loss:  tensor(0.7533, grad_fn=<NllLossBackward>)\n",
      "epoch:  800  loss:  tensor(0.7302, grad_fn=<NllLossBackward>)\n",
      "epoch:  800  loss:  tensor(0.7325, grad_fn=<NllLossBackward>)\n",
      "epoch:  810  loss:  tensor(0.7733, grad_fn=<NllLossBackward>)\n",
      "epoch:  810  loss:  tensor(0.7081, grad_fn=<NllLossBackward>)\n",
      "epoch:  820  loss:  tensor(0.7550, grad_fn=<NllLossBackward>)\n",
      "epoch:  820  loss:  tensor(0.7744, grad_fn=<NllLossBackward>)\n",
      "epoch:  830  loss:  tensor(0.7494, grad_fn=<NllLossBackward>)\n",
      "epoch:  830  loss:  tensor(0.7282, grad_fn=<NllLossBackward>)\n",
      "epoch:  840  loss:  tensor(0.7681, grad_fn=<NllLossBackward>)\n",
      "epoch:  840  loss:  tensor(0.7360, grad_fn=<NllLossBackward>)\n",
      "epoch:  850  loss:  tensor(0.7259, grad_fn=<NllLossBackward>)\n",
      "epoch:  850  loss:  tensor(0.7603, grad_fn=<NllLossBackward>)\n",
      "epoch:  860  loss:  tensor(0.7516, grad_fn=<NllLossBackward>)\n",
      "epoch:  860  loss:  tensor(0.7445, grad_fn=<NllLossBackward>)\n",
      "epoch:  870  loss:  tensor(0.7128, grad_fn=<NllLossBackward>)\n",
      "epoch:  870  loss:  tensor(0.7394, grad_fn=<NllLossBackward>)\n",
      "epoch:  880  loss:  tensor(0.7178, grad_fn=<NllLossBackward>)\n",
      "epoch:  880  loss:  tensor(0.7582, grad_fn=<NllLossBackward>)\n",
      "epoch:  890  loss:  tensor(0.7289, grad_fn=<NllLossBackward>)\n",
      "epoch:  890  loss:  tensor(0.7404, grad_fn=<NllLossBackward>)\n",
      "epoch:  900  loss:  tensor(0.7216, grad_fn=<NllLossBackward>)\n",
      "epoch:  900  loss:  tensor(0.7024, grad_fn=<NllLossBackward>)\n",
      "epoch:  910  loss:  tensor(0.7267, grad_fn=<NllLossBackward>)\n",
      "epoch:  910  loss:  tensor(0.7165, grad_fn=<NllLossBackward>)\n",
      "epoch:  920  loss:  tensor(0.7219, grad_fn=<NllLossBackward>)\n",
      "epoch:  920  loss:  tensor(0.7508, grad_fn=<NllLossBackward>)\n",
      "epoch:  930  loss:  tensor(0.7276, grad_fn=<NllLossBackward>)\n",
      "epoch:  930  loss:  tensor(0.7774, grad_fn=<NllLossBackward>)\n",
      "epoch:  940  loss:  tensor(0.6907, grad_fn=<NllLossBackward>)\n",
      "epoch:  940  loss:  tensor(0.7139, grad_fn=<NllLossBackward>)\n",
      "epoch:  950  loss:  tensor(0.7166, grad_fn=<NllLossBackward>)\n",
      "epoch:  950  loss:  tensor(0.7274, grad_fn=<NllLossBackward>)\n",
      "epoch:  960  loss:  tensor(0.7569, grad_fn=<NllLossBackward>)\n",
      "epoch:  960  loss:  tensor(0.7409, grad_fn=<NllLossBackward>)\n",
      "epoch:  970  loss:  tensor(0.7128, grad_fn=<NllLossBackward>)\n",
      "epoch:  970  loss:  tensor(0.7426, grad_fn=<NllLossBackward>)\n",
      "epoch:  980  loss:  tensor(0.7205, grad_fn=<NllLossBackward>)\n",
      "epoch:  980  loss:  tensor(0.7137, grad_fn=<NllLossBackward>)\n",
      "epoch:  990  loss:  tensor(0.7257, grad_fn=<NllLossBackward>)\n",
      "epoch:  990  loss:  tensor(0.7368, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.003)\n",
    "#optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)  \n",
    "\n",
    "loss_list = []\n",
    "# Training the Model\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (X_y) in enumerate(train_loader):\n",
    "        \n",
    "        y = X_y[:,768]\n",
    "        #print(y)\n",
    "        X = X_y[:,0:(768)]#.tolist()\n",
    "        \n",
    "        #print(X)\n",
    "        #print(list(X.size()))\n",
    "        #print(len(y))\n",
    "        y = y.int()\n",
    "        #print(list(y.size()))\n",
    "        #print(len(y))\n",
    "        y =  torch.LongTensor(y.tolist())\n",
    "        #print(y)\n",
    "        # Forward + Backward + Optimize\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(torch.tensor(X))\n",
    "        loss = criterion(outputs, y)\n",
    "        #print(loss)\n",
    "        #print(model)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        loss_list.append(loss)\n",
    "        \n",
    "        if ((i) % 20 == 0) and (epoch % 10 == 0):\n",
    "            #print ('Epoch: [%d/%d], Step: [%d/%d], Loss: %.4f' \n",
    "            #       % (epoch+1, num_epochs, i+1, len(train_dataset)//batch_size, loss.data[0]))\n",
    "            print(\"epoch: \",  epoch, \" loss: \", loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2bfe3de44e0>]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the 10000 test images: 69 %\n"
     ]
    }
   ],
   "source": [
    "# Test the Model\n",
    "correct = 0\n",
    "total = 0\n",
    "for X_y in test_loader:\n",
    "    y = X_y[:,768]\n",
    "    y = y.int()\n",
    "    y =  torch.LongTensor(y.tolist())\n",
    "    #print(y)\n",
    "    X = X_y[:,0:(768)].tolist()\n",
    "    X = torch.tensor(X)\n",
    "    outputs = model(X)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += y.size(0)\n",
    "    correct += (predicted == y).sum()\n",
    "    \n",
    "print('Accuracy of the model on the 10000 test images: %d %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6600693240901213"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_dataset.int().tolist().count(0)/len(y_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'LogisticRegression' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-86-063f06631100>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: 'LogisticRegression' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "model[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 30000 # max: 69318\n",
    "x_dataset = torch.empty(num, 768)\n",
    "y_dataset = torch.empty(num)\n",
    "miss = 0\n",
    "i = 0\n",
    "for idx, row in label_data.iterrows():\n",
    "    if idx < num:\n",
    "        a, b = get_tesors(row, \"question\", \"title\", \"gsarti/covidbert-nli\")\n",
    "        if len(a[0]) != 1:\n",
    "            c = (a[0]*b[0])\n",
    "            x_dataset[i] = c\n",
    "            rel = 0\n",
    "            if row[\"relevancy\"]>0.01:\n",
    "                rel = 1\n",
    "            y_dataset[i] = rel\n",
    "            i+=1\n",
    "        else:\n",
    "            miss +=1\n",
    "        if idx % 1000 == 0:\n",
    "            print(idx)\n",
    "print(miss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_dataset = x_dataset[0:(num-miss)]\n",
    "y_dataset = y_dataset[0:(num-miss)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([[1,2],[3,4],[5,6],[7,8],[9,10]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3,  4],\n",
       "        [ 5,  6],\n",
       "        [ 9, 10]])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[[1,2,4]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
